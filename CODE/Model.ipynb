{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from netCDF4 import Dataset\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import datetime as dt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the paths\n",
    "data_path = '/Users/justinhudson/Documents/HW/ATS_780/Homework_2/DATA/'\n",
    "figure_path = '/Users/justinhudson/Documents/HW/ATS_780/Homework_2/FIGURES/'\n",
    "root = '/Users/justinhudson/Documents/HW/ATS_780/Homework_2/CODE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the seed\n",
    "rand_seed = 144\n",
    "np.random.seed(rand_seed)\n",
    "tf.random.set_seed(rand_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bring in the data\n",
    "os.chdir(data_path)\n",
    "e5data = Dataset('ERA5_200hpa_U_V_relVort_Colorado_2021_2022.nc')\n",
    "u = e5data.variables['u'][:]\n",
    "v = e5data.variables['v'][:]\n",
    "vort = e5data.variables['vo'][:]\n",
    "lats = e5data.variables['latitude'][:]\n",
    "lons = e5data.variables['longitude'][:]\n",
    "time = e5data.variables['time'][:]\n",
    "#convert times to usable dates\n",
    "ref_date = dt.datetime(1900,1,1)\n",
    "dates = np.array( [ ref_date + dt.timedelta(hours = int(t)) for t in time ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the data\n",
    "def normalize_data(dataset:np.ndarray) -> np.ndarray:\n",
    "    '''\n",
    "        Normalizes data so that it is on the range 0-1 and then returns\n",
    "        the normalized data.\n",
    "\n",
    "        Inputs:\n",
    "            dataset (np.ndarray): The dataset to be normalized\n",
    "        \n",
    "        Outputs:\n",
    "            norm_data (np.ndarray): The normalized data\n",
    "    '''\n",
    "\n",
    "    data_min = np.nanmin(dataset)\n",
    "    data_max = np.nanmax(dataset)\n",
    "\n",
    "    norm_data = (dataset[:] - data_min) / (data_max - data_min)\n",
    "\n",
    "    return norm_data, data_min, data_max\n",
    "\n",
    "def denormalize_data(normed_data:np.ndarray,orig_min:float,orig_max:float) -> np.ndarray:\n",
    "    '''\n",
    "        De-normalizes a dataset using the min and max from the\n",
    "        original dataset.\n",
    "\n",
    "        Inputs:\n",
    "            normed_data (np.ndarray): The dataset to be de-normalized, should\n",
    "                have a range of [0-1]\n",
    "            orig_min (float): The original minima of the dataset which was\n",
    "                used to normalize it\n",
    "            orig_max (float): The original maxima of the dataset which was\n",
    "                used to normalize it\n",
    "        \n",
    "        Returns:\n",
    "            denormed_data (np.ndarray): The denormalized dataset which should\n",
    "                have a range of [orig_min,orig_max]\n",
    "    '''\n",
    "\n",
    "    denormed_data = (normed_data * (orig_max - orig_min)) + orig_min\n",
    "\n",
    "    return denormed_data\n",
    "\n",
    "u_norm,u_min,u_max = normalize_data(u)\n",
    "v_norm,v_min,v_max = normalize_data(v)\n",
    "vort_norm,vort_min,vort_max = normalize_data(vort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine u and v such that they are images with 2 \"channels\"\n",
    "uv_data = np.empty((u.shape[0],u.shape[1],u.shape[2],2))\n",
    "uv_data[:,:,:,0] = u_norm[:]\n",
    "uv_data[:,:,:,1] = v_norm[:]\n",
    "# uv_data is a 4D array of shape (time,lat,lon,channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING, VALIDATION, AND TESTING SHAPES:\n",
      "XTRAIN: (12614, 25, 41, 2), XVAL: (3154, 25, 41, 2), XTEST: (1752, 25, 41, 2)\n",
      "YTRAIN: (12614, 25, 41), YVAL: (3154, 25, 41), YTEST: (1752, 25, 41)\n"
     ]
    }
   ],
   "source": [
    "# Split the data in testing/validation/training\n",
    "# 10% will be testing\n",
    "# 20% of the remainder will be validation\n",
    "# the remainder of that will be training data\n",
    "\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(uv_data,vort_norm,test_size=0.1,\n",
    "                                                 shuffle=True, random_state= rand_seed)\n",
    "#now split off the validation from the training\n",
    "x_train,x_val,y_train,y_val = train_test_split(x_train,y_train,test_size=0.2,\n",
    "                                               shuffle = True,random_state= rand_seed)\n",
    "\n",
    "# print the shapes to verify things look right\n",
    "print(\"TRAINING, VALIDATION, AND TESTING SHAPES:\")\n",
    "print(f'XTRAIN: {x_train.shape}, XVAL: {x_val.shape}, XTEST: {x_test.shape}')\n",
    "print(f'YTRAIN: {y_train.shape}, YVAL: {y_val.shape}, YTEST: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Loss Functions Are Defined Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want our loss function to be done pixel wise because the goal is to recreate the entire relative vorticity field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eddy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
